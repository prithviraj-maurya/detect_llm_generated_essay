{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7441fbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:20:10.978837Z",
     "iopub.status.busy": "2023-11-17T01:20:10.977850Z",
     "iopub.status.idle": "2023-11-17T01:20:30.959461Z",
     "shell.execute_reply": "2023-11-17T01:20:30.958177Z"
    },
    "papermill": {
     "duration": 19.996594,
     "end_time": "2023-11-17T01:20:30.962738",
     "exception": false,
     "start_time": "2023-11-17T01:20:10.966144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa1f8a",
   "metadata": {
    "papermill": {
     "duration": 0.008774,
     "end_time": "2023-11-17T01:20:30.981491",
     "exception": false,
     "start_time": "2023-11-17T01:20:30.972717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ref: https://www.kaggle.com/code/rsuhara/ai-generated-text-detection-quick-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2119e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:20:31.003166Z",
     "iopub.status.busy": "2023-11-17T01:20:31.001130Z",
     "iopub.status.idle": "2023-11-17T01:20:42.639751Z",
     "shell.execute_reply": "2023-11-17T01:20:42.637903Z"
    },
    "papermill": {
     "duration": 11.653134,
     "end_time": "2023-11-17T01:20:42.643553",
     "exception": false,
     "start_time": "2023-11-17T01:20:30.990419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2078, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Cars. Cars have been around since they became ...      0\n",
       "1  Transportation is a large necessity in most co...      0\n",
       "2  \"America's love affair with it's vehicles seem...      0\n",
       "3  How often do you ride in a car? Do you drive a...      0\n",
       "4  Cars are a wonderful thing. They are perhaps o...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data\n",
    "train_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n",
    "test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\n",
    "train_prompts = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")\n",
    "\n",
    "\n",
    "ai_generated_train_essays = pd.read_csv(\"/kaggle/input/llm-generated-essays/ai_generated_train_essays.csv\")\n",
    "ai_generated_train_essays_gpt4 = pd.read_csv(\"/kaggle/input/llm-generated-essays/ai_generated_train_essays_gpt-4.csv\")\n",
    "\n",
    "\n",
    "daigt_external_dataset_1 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_01.csv\")\n",
    "daigt_external_dataset_2 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv\")\n",
    "daigt_external_dataset_3 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_03.csv\")\n",
    "daigt_external_dataset_4 = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\")\n",
    "daigt_external_dataset = pd.concat([daigt_external_dataset_1, daigt_external_dataset_2, daigt_external_dataset_3, daigt_external_dataset_4])\n",
    "daigt_external_dataset.drop([\"source\", \"essay_id\", \"prompt\"], axis=1, inplace=True)\n",
    "daigt_external_dataset_train = daigt_external_dataset[daigt_external_dataset.fold != 0].drop(\"fold\", axis=1)\n",
    "daigt_external_dataset_val = daigt_external_dataset[daigt_external_dataset.fold == 0].drop(\"fold\", axis=1)\n",
    "\n",
    "\n",
    "train_essays = pd.concat([train_essays, ai_generated_train_essays, ai_generated_train_essays_gpt4])\n",
    "train_essays['label'] = train_essays['generated']\n",
    "train_essays.drop([\"id\", \"prompt_id\", \"generated\"], inplace=True, axis=1)\n",
    "print(train_essays.shape)\n",
    "train_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e526bf2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:20:42.665463Z",
     "iopub.status.busy": "2023-11-17T01:20:42.664962Z",
     "iopub.status.idle": "2023-11-17T01:20:42.704297Z",
     "shell.execute_reply": "2023-11-17T01:20:42.702640Z"
    },
    "papermill": {
     "duration": 0.054201,
     "end_time": "2023-11-17T01:20:42.707512",
     "exception": false,
     "start_time": "2023-11-17T01:20:42.653311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (161534, 2)\n"
     ]
    }
   ],
   "source": [
    "## Split the dataset\n",
    "# train_essays, val_essays = train_test_split(train_essays, test_size=0.33)\n",
    "## Merge with external dataset\n",
    "# train_essays = pd.concat([daigt_external_dataset_train, train_essays])\n",
    "# val_essays = pd.concat([daigt_external_dataset_val, val_essays])\n",
    "train_essays = pd.concat([train_essays, daigt_external_dataset.drop('fold', axis=1)])\n",
    "print(\"Train size\", train_essays.shape)\n",
    "# print(\"Val size\", val_essays.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5574e4",
   "metadata": {
    "papermill": {
     "duration": 0.010982,
     "end_time": "2023-11-17T01:20:42.728232",
     "exception": false,
     "start_time": "2023-11-17T01:20:42.717250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68839779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:20:42.749166Z",
     "iopub.status.busy": "2023-11-17T01:20:42.748679Z",
     "iopub.status.idle": "2023-11-17T01:21:48.542270Z",
     "shell.execute_reply": "2023-11-17T01:21:48.540123Z"
    },
    "papermill": {
     "duration": 65.808831,
     "end_time": "2023-11-17T01:21:48.546438",
     "exception": false,
     "start_time": "2023-11-17T01:20:42.737607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_essays['text'], test_essays['text']], axis=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=50000)\n",
    "X = vectorizer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3728393",
   "metadata": {
    "papermill": {
     "duration": 0.009608,
     "end_time": "2023-11-17T01:21:48.566178",
     "exception": false,
     "start_time": "2023-11-17T01:21:48.556570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Word2Vec\n",
    "\n",
    "ref: https://www.kaggle.com/code/nkitgupta/text-representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25c86a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:21:48.589410Z",
     "iopub.status.busy": "2023-11-17T01:21:48.587800Z",
     "iopub.status.idle": "2023-11-17T01:27:49.341757Z",
     "shell.execute_reply": "2023-11-17T01:27:49.340502Z"
    },
    "papermill": {
     "duration": 360.780296,
     "end_time": "2023-11-17T01:27:49.356311",
     "exception": false,
     "start_time": "2023-11-17T01:21:48.576015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21/3006100231.py:4: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(Glove_path, word2vec_output_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Word Embeddings of word 'human' \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.6608e-01,  3.1670e-01, -5.8249e-01, -3.0978e-01, -4.3342e-02,\n",
       "       -2.7902e-01, -2.2359e-01,  1.5822e-01,  1.4204e-01, -2.5546e+00,\n",
       "        1.4570e-01, -2.4335e-01, -7.9048e-01, -7.0345e-02,  3.6125e-02,\n",
       "        8.6590e-02,  7.9128e-01,  8.8366e-01, -3.8760e-01, -2.5363e-01,\n",
       "       -2.1893e-01,  2.9416e-01, -1.0171e-01,  1.3125e-01,  1.7897e-01,\n",
       "        5.8697e-01,  9.8880e-01,  1.3927e-01,  4.0796e-01,  1.0456e-02,\n",
       "        8.6774e-03,  5.1483e-01, -1.1121e+00, -5.1464e-01,  9.6359e-02,\n",
       "        1.8087e-01,  3.3565e-01,  2.4491e-01, -2.3970e-01, -3.6623e-01,\n",
       "        5.1139e-01,  2.0225e-01, -9.9939e-02, -2.1025e-01, -4.4924e-01,\n",
       "        2.7756e-01, -4.3422e-01,  2.9502e-01,  3.0119e-01,  7.0748e-02,\n",
       "       -4.7604e-02,  5.4410e-01, -2.1035e-01,  9.3486e-02, -1.6013e-01,\n",
       "       -6.2257e-02,  1.9005e-01, -4.4857e-01, -1.6407e-01, -2.2538e-01,\n",
       "        1.6229e-01,  2.2353e-01,  1.4428e-01, -1.4320e-01, -5.4452e-01,\n",
       "       -1.5810e-01,  1.6613e-01,  3.0517e-01,  2.2682e-01,  2.3392e-01,\n",
       "        1.4420e-02,  2.3581e-01,  3.3901e-01, -1.3515e-01,  1.2504e-01,\n",
       "        5.2091e-02,  1.7347e-01,  2.0413e-01,  1.4869e-01,  6.9364e-01,\n",
       "        4.2607e-02, -2.7914e-01, -4.2708e-02,  8.6777e-01, -2.7702e-01,\n",
       "       -1.6653e-01,  1.7128e-01,  2.4892e-01,  2.7636e-01, -5.9533e-01,\n",
       "       -4.0766e-01,  7.6787e-02, -3.2353e-01,  2.8717e-01,  7.8707e-02,\n",
       "        2.8422e-01, -5.0156e-01,  1.6480e-01,  1.4438e-01, -3.4472e-01,\n",
       "        6.8599e-01, -6.5710e-01, -7.4509e-02, -2.2058e-01,  3.2522e-01,\n",
       "        5.7178e-01,  3.6560e-01,  1.9006e-02, -2.6290e-01,  5.7679e-02,\n",
       "        4.6301e-01,  2.1049e-01, -8.7795e-01,  4.1986e-01, -9.7955e-02,\n",
       "        1.1727e-01,  5.8366e-01,  3.3378e-01, -6.8787e-01, -9.3053e-02,\n",
       "       -5.4548e-01,  4.4119e-01,  3.2057e-01,  6.9433e-01, -8.3096e-01,\n",
       "       -4.8262e-01, -1.8561e-01,  6.5913e-01, -1.3943e-01,  5.3444e-02,\n",
       "       -1.9355e-01, -3.0163e-01,  2.7448e-01, -7.6775e-02, -3.5173e-01,\n",
       "       -1.9312e-01,  2.0715e-01,  4.4466e-02, -4.1042e-01,  5.0207e-01,\n",
       "        1.1511e-01, -1.3306e-02, -1.2321e-01, -2.9420e-01,  5.0965e-03,\n",
       "       -1.2611e-01,  5.5238e-02,  4.2515e-01, -1.0139e+00, -2.9264e-01,\n",
       "        1.9368e-01, -5.9128e-01,  2.8595e-01,  2.7801e-01, -1.5338e-01,\n",
       "        1.8042e-01, -4.4115e-01,  8.0668e-02,  1.0496e-01, -1.4847e-01,\n",
       "        4.0407e-01,  2.0501e-01,  6.7686e-01, -1.2744e-01,  8.3360e-02,\n",
       "        1.8603e-01,  6.8722e-01, -2.1671e-01, -2.6148e-01, -3.1682e-02,\n",
       "       -4.4320e-02, -2.0805e-01, -2.5868e-01,  7.5387e-02, -5.7802e-01,\n",
       "       -1.9793e-01,  5.4040e-02, -7.5155e-02, -1.9803e-01, -7.5996e-02,\n",
       "       -1.0914e-01, -3.0985e-01,  2.5827e-01, -2.3484e-01, -3.2249e-01,\n",
       "       -4.9973e-01, -4.9038e-01, -1.9788e-01,  4.0958e-01, -2.5788e-01,\n",
       "        6.5527e-02, -6.6362e-01, -3.9411e-02, -2.3160e-01, -1.8412e-02,\n",
       "        4.8032e-01,  4.6074e-01, -4.9403e-01, -1.3993e-01,  3.3578e-01,\n",
       "        5.1559e-01,  7.9922e-02,  4.4496e-01, -9.7533e-02,  7.5394e-03,\n",
       "        4.2994e-01, -2.1932e-01,  2.0696e-01,  9.8378e-03,  2.6022e-01,\n",
       "        2.6218e-01,  4.8072e-02, -1.6135e-01, -3.7569e-01, -1.6533e-01,\n",
       "        8.3233e-01, -1.0609e-01, -1.8695e-01,  7.8082e-03,  2.1870e-01,\n",
       "       -6.5372e-01, -7.7777e-02, -3.6130e-01,  4.3058e-01,  2.2788e-01,\n",
       "        1.3172e-02, -8.6183e-02,  3.7470e-01, -5.8307e-01,  6.5118e-01,\n",
       "        3.6204e-01, -2.8726e-01, -3.8916e-02, -4.9841e-01, -4.9983e-01,\n",
       "        2.3650e-01, -2.7696e-01, -2.7693e-01, -1.9759e-01, -3.6214e-01,\n",
       "       -2.2412e-01,  8.1860e-02,  9.0234e-01, -5.4989e-01, -9.2574e-01,\n",
       "       -6.2176e-04,  3.4262e-01,  2.6824e-01,  1.1086e-02,  6.1992e-01,\n",
       "        1.5994e-01, -1.5260e-02, -1.0169e-01,  1.1510e-01,  7.8099e-01,\n",
       "        5.4375e-01, -2.3922e-03, -7.9489e-01, -4.1774e-01,  5.7822e-01,\n",
       "       -6.7492e-02, -3.7620e-01,  4.2536e-01,  1.0234e-01,  1.9731e-01,\n",
       "        3.9849e-01, -2.6960e-01,  4.0959e-01, -5.3788e-01,  4.2295e-01,\n",
       "        2.1651e-01,  3.7772e-01,  3.2295e-01,  2.4570e-01,  9.5233e-03,\n",
       "        3.6473e-01, -2.0200e+00, -2.2543e-01,  6.7088e-01, -1.8870e-01,\n",
       "       -2.1337e-01, -7.3625e-01,  5.5594e-01,  2.8003e-01, -5.1877e-01,\n",
       "       -6.1657e-02,  1.5836e-01,  2.8019e-01,  2.4515e-01,  1.7778e-01,\n",
       "       -3.3345e-01, -6.8802e-01, -1.9556e-01, -1.1132e-01,  1.0925e-01,\n",
       "        3.8288e-01, -2.7935e-01,  2.4013e-01,  8.8691e-02,  4.6489e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Glove_path = \"/kaggle/input/glove6b/glove.6B.300d.txt\"\n",
    "\n",
    "word2vec_output_file = 'glove.6B.300d.txt.word2vec'\n",
    "glove2word2vec(Glove_path, word2vec_output_file)\n",
    "\n",
    "# load the Stanford GloVe model\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "\n",
    "print(\"Glove Word Embeddings of word 'human' \")\n",
    "glove_model['human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8fad72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:27:49.379592Z",
     "iopub.status.busy": "2023-11-17T01:27:49.379134Z",
     "iopub.status.idle": "2023-11-17T01:27:49.390446Z",
     "shell.execute_reply": "2023-11-17T01:27:49.388817Z"
    },
    "papermill": {
     "duration": 0.026808,
     "end_time": "2023-11-17T01:27:49.393624",
     "exception": false,
     "start_time": "2023-11-17T01:27:49.366816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_tsne(model, num):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    for word in model.key_to_index:\n",
    "        if word not in stop_words:\n",
    "            tokens.append(np.array(model[word]))\n",
    "            labels.append(word)\n",
    "    tsne = TSNE(perplexity = 40, n_components = 2, init = 'pca', n_iter = 2500, random_state = 23)\n",
    "    data = tsne.fit_transform(np.array(tokens[:num]))\n",
    "    x = []\n",
    "    y = []\n",
    "    for each in data:\n",
    "        x.append(each[0])\n",
    "        y.append(each[1])\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    for i in range(num):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy = (x[i], y[i]),\n",
    "                     xytext = (5,2),\n",
    "                     textcoords = 'offset points',\n",
    "                     ha = 'right',\n",
    "                     va = 'bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fca9c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:27:49.418501Z",
     "iopub.status.busy": "2023-11-17T01:27:49.417874Z",
     "iopub.status.idle": "2023-11-17T01:27:49.423957Z",
     "shell.execute_reply": "2023-11-17T01:27:49.422405Z"
    },
    "papermill": {
     "duration": 0.021705,
     "end_time": "2023-11-17T01:27:49.427021",
     "exception": false,
     "start_time": "2023-11-17T01:27:49.405316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#visualising the cbow archtecture(only the first 300)\n",
    "# plot_tsne(glove_model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c246b3c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:27:49.450468Z",
     "iopub.status.busy": "2023-11-17T01:27:49.450009Z",
     "iopub.status.idle": "2023-11-17T01:27:49.459270Z",
     "shell.execute_reply": "2023-11-17T01:27:49.457865Z"
    },
    "papermill": {
     "duration": 0.024649,
     "end_time": "2023-11-17T01:27:49.462560",
     "exception": false,
     "start_time": "2023-11-17T01:27:49.437911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/code/eswarbabu88/toxic-comment-glove-logistic-regression\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(glove_model[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffaecdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:27:49.486715Z",
     "iopub.status.busy": "2023-11-17T01:27:49.486173Z",
     "iopub.status.idle": "2023-11-17T01:48:43.065185Z",
     "shell.execute_reply": "2023-11-17T01:48:43.061908Z"
    },
    "papermill": {
     "duration": 1253.606168,
     "end_time": "2023-11-17T01:48:43.079457",
     "exception": false,
     "start_time": "2023-11-17T01:27:49.473289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_essays['text'], test_essays['text']], axis=0)\n",
    "\n",
    "X = np.array([sent2vec(sent) for sent in df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae73ef",
   "metadata": {
    "papermill": {
     "duration": 0.118927,
     "end_time": "2023-11-17T01:48:43.216426",
     "exception": false,
     "start_time": "2023-11-17T01:48:43.097499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3882f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:48:43.244089Z",
     "iopub.status.busy": "2023-11-17T01:48:43.243621Z",
     "iopub.status.idle": "2023-11-17T01:49:27.048423Z",
     "shell.execute_reply": "2023-11-17T01:49:27.046263Z"
    },
    "papermill": {
     "duration": 43.82451,
     "end_time": "2023-11-17T01:49:27.056138",
     "exception": false,
     "start_time": "2023-11-17T01:48:43.231628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC for fold 1: 0.9877\n",
      "ROC AUC for fold 2: 0.9871\n",
      "ROC AUC for fold 3: 0.9867\n",
      "ROC AUC for fold 4: 0.9873\n",
      "ROC AUC for fold 5: 0.9886\n",
      "Average ROC AUC: 0.9875\n",
      "Standard deviation: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "auc_scores = []\n",
    "\n",
    "# Split the data into training and validation for each fold\n",
    "for train_idx, val_idx in cv.split(X[:train_essays.shape[0]], train_essays['label']):\n",
    "    X_train, X_val = X[:train_essays.shape[0]][train_idx], X[:train_essays.shape[0]][val_idx]\n",
    "    y_train, y_val = train_essays['label'].iloc[train_idx], train_essays['label'].iloc[val_idx]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class on the validation data\n",
    "    preds_val_lr = lr_model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC score for the validation set\n",
    "    auc_score = roc_auc_score(y_val, preds_val_lr)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "# Print the scores for each fold\n",
    "for i, score in enumerate(auc_scores, 1):\n",
    "    print(f'ROC AUC for fold {i}: {score:.4f}')\n",
    "\n",
    "print('Average ROC AUC:', round(sum(auc_scores)/len(auc_scores), 4))\n",
    "print('Standard deviation:', round((sum([(x - sum(auc_scores)/len(auc_scores))**2 for x in auc_scores])/len(auc_scores))**0.5, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62359732",
   "metadata": {
    "papermill": {
     "duration": 0.023082,
     "end_time": "2023-11-17T01:49:27.104148",
     "exception": false,
     "start_time": "2023-11-17T01:49:27.081066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628973df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T01:49:27.146600Z",
     "iopub.status.busy": "2023-11-17T01:49:27.146130Z",
     "iopub.status.idle": "2023-11-17T02:10:46.248517Z",
     "shell.execute_reply": "2023-11-17T02:10:46.246028Z"
    },
    "papermill": {
     "duration": 1279.132852,
     "end_time": "2023-11-17T02:10:46.262360",
     "exception": false,
     "start_time": "2023-11-17T01:49:27.129508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC for fold 1: 0.9998\n",
      "ROC AUC for fold 2: 0.9998\n",
      "ROC AUC for fold 3: 0.9999\n",
      "ROC AUC for fold 4: 0.9996\n",
      "ROC AUC for fold 5: 0.9999\n",
      "Average ROC AUC: 0.9998\n",
      "Standard deviation: 0.0001\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "auc_scores = []\n",
    "\n",
    "# Split the data into training and validation for each fold\n",
    "for train_idx, val_idx in cv.split(X[:train_essays.shape[0]], train_essays['label']):\n",
    "    X_train, X_val = X[:train_essays.shape[0]][train_idx], X[:train_essays.shape[0]][val_idx]\n",
    "    y_train, y_val = train_essays['label'].iloc[train_idx], train_essays['label'].iloc[val_idx]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class on the validation data\n",
    "    preds_val_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC score for the validation set\n",
    "    auc_score = roc_auc_score(y_val, preds_val_xgb)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "# Print the scores for each fold\n",
    "for i, score in enumerate(auc_scores, 1):\n",
    "    print(f'ROC AUC for fold {i}: {score:.4f}')\n",
    "\n",
    "print('Average ROC AUC:', round(sum(auc_scores)/len(auc_scores), 4))\n",
    "print('Standard deviation:', round((sum([(x - sum(auc_scores)/len(auc_scores))**2 for x in auc_scores])/len(auc_scores))**0.5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0963060c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T02:10:46.290132Z",
     "iopub.status.busy": "2023-11-17T02:10:46.287746Z",
     "iopub.status.idle": "2023-11-17T02:15:06.472824Z",
     "shell.execute_reply": "2023-11-17T02:15:06.470865Z"
    },
    "papermill": {
     "duration": 260.213813,
     "end_time": "2023-11-17T02:15:06.487321",
     "exception": false,
     "start_time": "2023-11-17T02:10:46.273508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     23349\n",
      "           1       1.00      0.98      0.99      8957\n",
      "\n",
      "    accuracy                           0.99     32306\n",
      "   macro avg       1.00      0.99      0.99     32306\n",
      "weighted avg       0.99      0.99      0.99     32306\n",
      "\n",
      "Accuracy: 0.9911081465152366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the ensemble model\n",
    "ensemble = VotingClassifier(estimators=[('lr', lr_model), ('xgb', xgb_model)], voting='soft')\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = ensemble.predict(X_val)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f'Accuracy: {roc_auc_score(y_val, y_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18336ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T02:15:06.513430Z",
     "iopub.status.busy": "2023-11-17T02:15:06.512964Z",
     "iopub.status.idle": "2023-11-17T02:15:07.362446Z",
     "shell.execute_reply": "2023-11-17T02:15:07.361037Z"
    },
    "papermill": {
     "duration": 0.865965,
     "end_time": "2023-11-17T02:15:07.365294",
     "exception": false,
     "start_time": "2023-11-17T02:15:06.499329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train: 0.9999210768985691\n"
     ]
    }
   ],
   "source": [
    "preds_train = ensemble.predict_proba(X[:train_essays.shape[0]])[:,1]\n",
    "preds_test = ensemble.predict_proba(X[train_essays.shape[0]:])[:,1]\n",
    "print('ROC AUC train:', roc_auc_score(train_essays['label'], preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76c11fda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T02:15:07.390451Z",
     "iopub.status.busy": "2023-11-17T02:15:07.389937Z",
     "iopub.status.idle": "2023-11-17T02:15:07.414825Z",
     "shell.execute_reply": "2023-11-17T02:15:07.413912Z"
    },
    "papermill": {
     "duration": 0.041066,
     "end_time": "2023-11-17T02:15:07.417846",
     "exception": false,
     "start_time": "2023-11-17T02:15:07.376780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':test_essays[\"id\"],'generated':preds_test}).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "480c54db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T02:15:07.531744Z",
     "iopub.status.busy": "2023-11-17T02:15:07.531226Z",
     "iopub.status.idle": "2023-11-17T02:15:07.539414Z",
     "shell.execute_reply": "2023-11-17T02:15:07.537811Z"
    },
    "papermill": {
     "duration": 0.023844,
     "end_time": "2023-11-17T02:15:07.542292",
     "exception": false,
     "start_time": "2023-11-17T02:15:07.518448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_all_file_paths(directory):\n",
    "  \n",
    "#     # initializing empty file paths list\n",
    "#     file_paths = []\n",
    "  \n",
    "#     # crawling through directory and subdirectories\n",
    "#     for root, directories, files in os.walk(directory):\n",
    "#         for filename in files:\n",
    "#             # join the two strings in order to form the full filepath.\n",
    "#             filepath = os.path.join(root, filename)\n",
    "#             file_paths.append(filepath)\n",
    "  \n",
    "#     # returning all file paths\n",
    "#     return file_paths        \n",
    "  \n",
    "# def main():\n",
    "#     # path to folder which needs to be zipped\n",
    "#     directory = '../input/language-tool-python-2-7-1/LanguageTool-5.7/LanguageTool-5.7'\n",
    "  \n",
    "#     # calling function to get all file paths in the directory\n",
    "#     file_paths = get_all_file_paths(directory)\n",
    "\n",
    "#     # writing files to a zipfile\n",
    "#     with ZipFile('./lt.zip','w') as zip:\n",
    "#         # writing each file one by one\n",
    "#         for file in file_paths:\n",
    "#             zip.write(file)\n",
    "  \n",
    "#     print('All files zipped successfully!')        \n",
    "    \n",
    "# main()\n",
    "\n",
    "\n",
    " \n",
    "# zip_file = \"./lt.zip\"\n",
    " \n",
    "# try:\n",
    "#     with zipfile.ZipFile(zip_file) as z:\n",
    "#         z.extractall()\n",
    "#         print(\"Extracted all\")\n",
    "# except:\n",
    "#     print(\"Invalid file\")\n",
    "    \n",
    "# #move to cache\n",
    "# !mv {'./input/language-tool-python-2-7-1/LanguageTool-5.7/LanguageTool-5.7'} {lt_path} \n",
    "# print(os.listdir('/root/.cache/language_tool_python/'))\n",
    "\n",
    "# #remove files from output\n",
    "\n",
    "# shutil.rmtree('./input')\n",
    "# os.remove(\"./lt.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b6f13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T02:15:07.566829Z",
     "iopub.status.busy": "2023-11-17T02:15:07.566267Z",
     "iopub.status.idle": "2023-11-17T02:15:07.572021Z",
     "shell.execute_reply": "2023-11-17T02:15:07.570705Z"
    },
    "papermill": {
     "duration": 0.021527,
     "end_time": "2023-11-17T02:15:07.574958",
     "exception": false,
     "start_time": "2023-11-17T02:15:07.553431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import language_tool_python\n",
    "# correcter = language_tool_python.LanguageTool('en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e0cd956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T02:15:07.599062Z",
     "iopub.status.busy": "2023-11-17T02:15:07.598540Z",
     "iopub.status.idle": "2023-11-17T02:15:07.605045Z",
     "shell.execute_reply": "2023-11-17T02:15:07.603511Z"
    },
    "papermill": {
     "duration": 0.022118,
     "end_time": "2023-11-17T02:15:07.607913",
     "exception": false,
     "start_time": "2023-11-17T02:15:07.585795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import language_tool_python\n",
    "# tool = language_tool_python.LanguageTool('en-US')\n",
    "# def how_many_typos(text):    \n",
    "#     return len(tool.check(text))\n",
    "\n",
    "# train_essays['ntypos']=train_essays['text'].apply(lambda x: how_many_typos(x))\n",
    "# train_essays['pred'] = -train_essays['ntypos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "816f032b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T02:15:07.631739Z",
     "iopub.status.busy": "2023-11-17T02:15:07.631226Z",
     "iopub.status.idle": "2023-11-17T02:15:07.636962Z",
     "shell.execute_reply": "2023-11-17T02:15:07.635599Z"
    },
    "papermill": {
     "duration": 0.021114,
     "end_time": "2023-11-17T02:15:07.639856",
     "exception": false,
     "start_time": "2023-11-17T02:15:07.618742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502851f",
   "metadata": {
    "papermill": {
     "duration": 0.010601,
     "end_time": "2023-11-17T02:15:07.661418",
     "exception": false,
     "start_time": "2023-11-17T02:15:07.650817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 32801,
     "sourceId": 42887,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3937441,
     "sourceId": 6868189,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3942644,
     "sourceId": 6890527,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3968241,
     "sourceId": 6909860,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3304.1875,
   "end_time": "2023-11-17T02:15:10.674486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-17T01:20:06.486986",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
